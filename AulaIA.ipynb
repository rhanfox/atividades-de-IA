{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IWYqVzZ1BfZ"
      },
      "outputs": [],
      "source": [
        "# Importando as bibiliotecas que eu vou utilizar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# função para criar um gerador\n",
        "def build_generator(latent_dim, output_shape):\n",
        "  model = tf.keras.Sequential()\n",
        "  model = add(layers.BatchNormalization())\n",
        "  model = add(layers.Dense(512, activation='relu'))\n",
        "  model = add(layers.BatchNormalization())\n",
        "  model = add(layers.Dense(1024, activation='relu'))\n",
        "  model = add(layers.BatchNormalization())\n",
        "  model = add(layers.Dense(output_shape, activation='tanh'))\n",
        "  return model\n",
        "\n",
        "  #função para criar o discriminador\n",
        "def build_discriminator(input_shape):\n",
        "  model = tf.keras.Sequential()\n",
        "  model = app(layers.Dense(1024,input_shape=(input_shape,), activation='relu'))\n",
        "  model = add(layers.Dropout(0.3))\n",
        "  model = add(layers.Dense(512, activation='relu'))\n",
        "  model = add(layers.Dropout(0.3))\n",
        "  model = add(layers.Dense(256, activation='relu'))\n",
        "  model = add(layers.Dropout(0.3))\n",
        "  model = add(layers.Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "  #função modelo gan\n",
        "def build_gan(generator, discriminator):\n",
        "  discriminator.trainable = False\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(generator)\n",
        "  model.add(discriminator)\n",
        "  return model\n",
        "\n",
        "  #dimensões\n",
        "latent_dim = 100\n",
        "output_shape = 784\n",
        "\n",
        "#criando as instâncias\n",
        "generator = build_generator(latent_dim, output_shape)\n",
        "discriminator = build_discriminator(output_shape)\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "  #compilações\n",
        "generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer='adam')"
      ],
      "metadata": {
        "id": "DiPigd-x5UHS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "f44de956-d43e-4f4b-f165-2bb091fd909e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'add' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8dcf556694bf>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m#criando as instâncias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-8dcf556694bf>\u001b[0m in \u001b[0;36mbuild_generator\u001b[0;34m(latent_dim, output_shape)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'add' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código uma vez treinado pode gerar novos dados que parecem pertencer ao mesmo conjunto de dados que foi usado para treinamento, como imagens que se assemelham a digitos manuscritos (por exemplo, MNIST)"
      ],
      "metadata": {
        "id": "HemgaFMUFTKs"
      }
    }
  ]
}